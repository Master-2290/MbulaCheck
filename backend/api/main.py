from fastapi import FastAPI, HTTPException, Query
from fastapi.responses import StreamingResponse, JSONResponse
from pydantic import BaseModel, Field
import joblib
import numpy as np
import pandas as pd
import os
import io
from datetime import date, timedelta, datetime

from models.utils import add_temporal_features, add_lags

# --------------------------
# Initialisation de l'app
# --------------------------
app = FastAPI(
    title="MbulaCheck API üå¶Ô∏è",
    description="API pour pr√©dire la m√©t√©o et la pluie √† Kinshasa √† partir de la date ou d'une p√©riode.",
    version="2.0.0"
)

# --------------------------
# Chargement des mod√®les et donn√©es historiques
# --------------------------
BASE_DIR = os.path.dirname(os.path.abspath(__file__))
MODEL_DIR = os.path.join(BASE_DIR, "..", "models")
DATA_PATH = os.path.join(BASE_DIR, "..", "data", "nasa_weather_2018_2025.csv")

try:
    REGRESSOR_PATH = os.path.join(MODEL_DIR, "MbulaCheck_regressor.pkl")
    CLASSIFIER_PATH = os.path.join(MODEL_DIR, "MbulaCheck_classifier.pkl")
    regressor = joblib.load(REGRESSOR_PATH)
    classifier = joblib.load(CLASSIFIER_PATH)
    print("‚úÖ Mod√®les charg√©s avec succ√®s.")
except Exception as e:
    print("‚ùå Erreur lors du chargement des mod√®les :", e)
    regressor, classifier = None, None

try:
    df_hist = pd.read_csv(DATA_PATH, parse_dates=["date"])
    print("‚úÖ Historique m√©t√©o charg√©.")
except Exception as e:
    print("‚ùå Erreur chargement de l'historique m√©t√©o:", e)
    df_hist = None

# --------------------------
# Helper : Pr√©parer les features pour une date/p√©riode
# --------------------------


def build_features_for_date(date_val, lags=[1, 3]):
    date_val = pd.to_datetime(date_val)
    needed_dates = [date_val - pd.Timedelta(days=lag) for lag in lags]
    for lag, d in zip(lags, needed_dates):
        if d not in df_hist['date'].values:
            return None  # donn√©es manquantes
    row = df_hist[df_hist['date'] == date_val].copy()
    if row.empty:
        return None
    row = add_temporal_features(row, date_col='date')
    df_with = pd.concat([df_hist, row], ignore_index=True)
    df_with = add_lags(df_with, ["Temperature_C", "Humidity_percent",
                       "Pressure_kPa", "Wind_m_s", "PRECTOTCORR"], lags=lags)
    last_row = df_with[df_with['date'] == date_val]
    return last_row


def build_features_for_period(start_date, end_date, lags=[1, 3]):
    period = pd.date_range(start=start_date, end=end_date)
    features = []
    for d in period:
        row = build_features_for_date(d, lags=lags)
        if row is not None and not row.empty:
            features.append(row)
    if features:
        return pd.concat(features, ignore_index=True)
    else:
        return pd.DataFrame()

# --------------------------
# Endpoint racine
# --------------------------


@app.get("/")
def home():
    return {"message": "Bienvenue sur l‚ÄôAPI MbulaCheck v2 üåç. Rendez-vous sur /docs pour tester."}

# --------------------------
# Endpoint de pr√©diction sur une p√©riode
# --------------------------


class PredictionRequest(BaseModel):
    start_date: date = Field(...,
                             description="Date de d√©but au format YYYY-MM-DD")
    end_date: date = Field(..., description="Date de fin au format YYYY-MM-DD")


@app.post("/predict/period")
def predict_period(req: PredictionRequest):
    if regressor is None or classifier is None or df_hist is None:
        raise HTTPException(
            status_code=500, detail="Mod√®les ou donn√©es historiques non disponibles.")

    # Validation des dates
    if req.end_date < req.start_date:
        raise HTTPException(
            status_code=400, detail="La date de fin doit √™tre apr√®s la date de d√©but.")
    # Pr√©paration des features
    features_df = build_features_for_period(req.start_date, req.end_date)
    if features_df.empty:
        raise HTTPException(
            status_code=400, detail="Impossible de g√©n√©rer les features pour cette p√©riode (donn√©es historiques manquantes).")

    # S√©lection des colonnes d'entr√©e
    input_cols = [c for c in features_df.columns if c not in [
        "date", "Temperature_C", "Humidity_percent", "Pressure_kPa", "Wind_m_s", "PRECTOTCORR"]]
    X = features_df[input_cols]

    # Pr√©dictions
    y_reg = regressor.predict(X)
    y_clf_proba = classifier.predict_proba(X)[:, 1]

    # R√©sultats
    results = []
    for i, row in features_df.iterrows():
        results.append({
            "date": row["date"].strftime("%Y-%m-%d"),
            "Temperature_C": round(float(y_reg[i, 0]), 2),
            "Humidity_percent": round(float(y_reg[i, 1]), 2),
            "Pressure_kPa": round(float(y_reg[i, 2]), 2),
            "Wind_m_s": round(float(y_reg[i, 3]), 2),
            "Rain_Probability": round(float(y_clf_proba[i]), 3)
        })
    return {"results": results}

# --------------------------
# Endpoint t√©l√©chargement CSV ou JSON
# --------------------------


@app.get("/download")
def download_results(
        start_date: date = Query(..., description="Date de d√©but YYYY-MM-DD"),
        end_date: date = Query(..., description="Date de fin YYYY-MM-DD"),
        format: str = Query("csv", description="Format: csv ou json")):
    if regressor is None or classifier is None or df_hist is None:
        raise HTTPException(
            status_code=500, detail="Mod√®les ou donn√©es historiques non disponibles.")
    if end_date < start_date:
        raise HTTPException(
            status_code=400, detail="La date de fin doit √™tre apr√®s la date de d√©but.")
    features_df = build_features_for_period(start_date, end_date)
    if features_df.empty:
        raise HTTPException(
            status_code=400, detail="Impossible de g√©n√©rer les features pour cette p√©riode (donn√©es historiques manquantes).")
    input_cols = [c for c in features_df.columns if c not in [
        "date", "Temperature_C", "Humidity_percent", "Pressure_kPa", "Wind_m_s", "PRECTOTCORR"]]
    X = features_df[input_cols]
    y_reg = regressor.predict(X)
    y_clf_proba = classifier.predict_proba(X)[:, 1]
    df_out = pd.DataFrame({
        "date": features_df["date"].dt.strftime("%Y-%m-%d"),
        "Temperature_C": y_reg[:, 0],
        "Humidity_percent": y_reg[:, 1],
        "Pressure_kPa": y_reg[:, 2],
        "Wind_m_s": y_reg[:, 3],
        "Rain_Probability": y_clf_proba
    })
    if format == "csv":
        stream = io.StringIO()
        df_out.to_csv(stream, index=False)
        stream.seek(0)
        return StreamingResponse(iter([stream.getvalue()]), media_type="text/csv",
                                 headers={"Content-Disposition": "attachment; filename=mbulacheck_results.csv"})
    elif format == "json":
        return JSONResponse(df_out.to_dict(orient="records"))
    else:
        raise HTTPException(
            status_code=400, detail="Format non support√© (csv ou json attendu)")

# --------------------------
# Endpoint statistiques sur la p√©riode
# --------------------------


@app.get("/period/stats")
def stats_period(
        start_date: date = Query(..., description="Date de d√©but YYYY-MM-DD"),
        end_date: date = Query(..., description="Date de fin YYYY-MM-DD")):
    if regressor is None or classifier is None or df_hist is None:
        raise HTTPException(
            status_code=500, detail="Mod√®les ou donn√©es historiques non disponibles.")
    if end_date < start_date:
        raise HTTPException(
            status_code=400, detail="La date de fin doit √™tre apr√®s la date de d√©but.")
    features_df = build_features_for_period(start_date, end_date)
    if features_df.empty:
        raise HTTPException(
            status_code=400, detail="Impossible de g√©n√©rer les features pour cette p√©riode (donn√©es historiques manquantes).")
    input_cols = [c for c in features_df.columns if c not in [
        "date", "Temperature_C", "Humidity_percent", "Pressure_kPa", "Wind_m_s", "PRECTOTCORR"]]
    X = features_df[input_cols]
    y_reg = regressor.predict(X)
    y_clf_proba = classifier.predict_proba(X)[:, 1]
    df_out = pd.DataFrame({
        "date": features_df["date"].dt.strftime("%Y-%m-%d"),
        "Temperature_C": y_reg[:, 0],
        "Humidity_percent": y_reg[:, 1],
        "Pressure_kPa": y_reg[:, 2],
        "Wind_m_s": y_reg[:, 3],
        "Rain_Probability": y_clf_proba
    })
    # Statistiques simples
    stats = {
        "Temperature_C_mean": round(df_out["Temperature_C"].mean(), 2),
        "Temperature_C_max": round(df_out["Temperature_C"].max(), 2),
        "Temperature_C_min": round(df_out["Temperature_C"].min(), 2),
        "Humidity_percent_mean": round(df_out["Humidity_percent"].mean(), 2),
        "Pressure_kPa_mean": round(df_out["Pressure_kPa"].mean(), 2),
        "Wind_m_s_mean": round(df_out["Wind_m_s"].mean(), 2),
        "Nb_days_rain_proba_gt_0.6": int((df_out["Rain_Probability"] > 0.6).sum())
    }
    return stats
